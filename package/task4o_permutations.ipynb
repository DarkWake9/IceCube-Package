{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read icdata\n",
      "read uptdata\n",
      "read eadata\n",
      "read mspdata\n"
     ]
    }
   ],
   "source": [
    "# from core import readfiles\n",
    "import numpy as np\n",
    "import os\n",
    "import multiprocessing as mul\n",
    "import matplotlib.pyplot as plt\n",
    "from numba import jit, njit, prange, set_num_threads, vectorize, guvectorize, cuda\n",
    "from tqdm import tqdm\n",
    "from core.signal_bag import *\n",
    "from core.stacking_analysis import *\n",
    "from core.req_arrays import *\n",
    "import pickle\n",
    "import scipy.stats as st\n",
    "import scipy.interpolate as interp\n",
    "# import torch\n",
    "# from core import weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_threads = int(mul.cpu_count()*0.9)\n",
    "set_num_threads(num_threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNCOMMENT FOR LINEAR BINS\n",
    "# all_enu = np.linspace(10**11.001, 10**18.999, 1000)\n",
    "all_enu = e_nu_wall\n",
    "\n",
    "# enus = 0.5*(all_enu[1:]+all_enu[:-1])\n",
    "# UNCOMMENT FOR DENSER LOGARITHMIC BINS, optimal nbins is 1e6\n",
    "enus = np.logspace(11.001, 18.999, int(1e5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "enus_bin_indices = np.zeros(len(enus), dtype=np.int64)\n",
    "\n",
    "for i in prange(len(enus)):\n",
    "    enus_bin_indices[i] = np.digitize(enus[i], e_nu_wall) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of energy bins:  100000\n",
      "\n",
      "Number of phi bins:  1000\n",
      "\n",
      "Calculating weights...\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gamma_arr = [-2, -2.2, -2.53, -3]\n",
    "phio = np.logspace(-38, -26, 1000) #CHANGING TO LINEAR BINS RESULTS IN STRAIGHT LINES\n",
    "\n",
    "# print(\"\\nNumber of threads: \", num_threads)\n",
    "print(\"\\nNumber of energy bins: \", len(enus))\n",
    "print(\"\\nNumber of phi bins: \", len(phio))\n",
    "print(\"\\nCalculating weights...\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "eareaa = [i.astype(np.float64) for i in earea]\n",
    "eareaa = np.asfarray(eareaa, dtype=np.float64)\n",
    "eareaa[0][0]\n",
    "earea2 = np.asfortranarray(earea)\n",
    "earea2 = earea2[0].astype(np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_models = np.column_stack([np.ones(p), 1/(msdist**2), mss1400]).T.astype(np.float64)\n",
    "sum_wt_model = [1, np.sum(1/(msdist**2)), np.sum(mss1400)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_PERM = np.arange(0, len(msdec), dtype=np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1413, 1808, 2272, ...,  660, 1718,  521])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.permutation( DEFAULT_PERM)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for perm in range(2):\n",
    "    prm = np.random.permutation( DEFAULT_PERM)\n",
    "    msdec = msdec[prm]\n",
    "\n",
    "    msdec_bin_indices = np.zeros(p, dtype=np.int64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for perm in range(2):\n",
    "    \n",
    "    dec_offest = 2\n",
    "    prm = np.random.permutation(DEFAULT_PERM)\n",
    "    msdec = msdec[prm] + 2*np.random.uniform(size=len(msdec))\n",
    "\n",
    "    msdec_bin_indices = np.zeros(p, dtype=np.int64)\n",
    "    for i in prange(p):\n",
    "        msdec_bin_indices[i] = np.digitize(msdec[i], dec_nu) - 1\n",
    "\n",
    "\n",
    "\n",
    "    @vectorize(['float64(int64, float64, int64)'], nopython=True, target='parallel')\n",
    "    def psr_wt_sing_gamma(psrno,gamma, season):\n",
    "\n",
    "        tt_upt = t_upt[season]\n",
    "        l = msdec_bin_indices[psrno]\n",
    "        wt_ac_temp = np.zeros(len(enus), dtype=np.float64)\n",
    "        for i in prange(len(enus)):\n",
    "            wt_ac_temp[i] = np.float64(tt_upt * earea[ea_season(season)][l*40 + enus_bin_indices[i]] * enus[i]**gamma)\n",
    "\n",
    "\n",
    "        return np.trapz(wt_ac_temp, enus)\n",
    "\n",
    "    wt_vec = psr_wt_sing_gamma(range(p), -1, 0)\n",
    "    w_models = np.column_stack([np.ones(p), 1/(msdist**2), mss1400]).T.astype(np.float64)\n",
    "    sum_wt_model = [1, np.sum(1/(msdist**2)), np.sum(mss1400)]\n",
    "    altier_path = [os.getcwd() + '/pickle/', os.getcwd() + '/../pickle/']\n",
    "    if f'wt_acc_{len(enus)}_bins_C_wt_perm_{perm}_do_{dec_offest}.pkl' in os.listdir(altier_path[0]):# or f'wt_acc.pkl_{len(enus)}' in os.listdir(altier_path[1]):\n",
    "        print(\"Loading wt_acc from pickle\")\n",
    "        # try:\n",
    "        #     wt_acc = pickle.load(altier_path[1] + f'wt_acc.pkl_{len(enus)//2}_bins')\n",
    "        # except:\n",
    "        with open(altier_path[0] + f'wt_acc_{len(enus)}_bins_C_wt_perm_{perm}_do_{dec_offest}.pkl', 'rb') as f:\n",
    "            wt_acc = pickle.load(f)\n",
    "        \n",
    "        \n",
    "        print(\"Loaded wt_acc from pickle with nbins= \", len(enus))\n",
    "\n",
    "    else:\n",
    "        print(\"Calculating wt_acc for all pulsars and seasons and gamma\")\n",
    "        wt_acc = []\n",
    "        for gamma in prange(len(gamma_arr)):\n",
    "            wt_allpsr = []\n",
    "            for season in tqdm(prange(10)):\n",
    "        \n",
    "\n",
    "                wt_allpsr.append(np.array(psr_wt_sing_gamma(prange(p), gamma_arr[gamma], season), dtype=np.float64))\n",
    "                # tmp = []\n",
    "            wt_acc.append(wt_allpsr)\n",
    "            wt_allpsr = []\n",
    "            \n",
    "        wt_acc = np.asfarray(wt_acc, dtype=np.float64)\n",
    "        with open(altier_path[0] + f'wt_acc_{len(enus)}_bins_C_wt_perm_{perm}_do_{dec_offest}.pkl', 'wb') as f:\n",
    "            pickle.dump(wt_acc, f)\n",
    "        print(\"Calculated wt_acc for all pulsars and seasons and gamma\")\n",
    "    season_walls = np.asarray([0, 36900, 143911, 237044, 373288, 486146, 608687, 735732, 865043, 988700, 1134450])\n",
    "    season_widts= np.diff(season_walls)\n",
    "    #Compute the signal PDF for all neutrinos as per eqns 6, 7 and weights as per eqn 8 of 2205.15963\n",
    "\n",
    "    @njit(nogil=True)\n",
    "    def S_ijk(nu): \n",
    "\n",
    "        '''\n",
    "        Calculates S_ij as in EQN 7 of 2205.15963\n",
    "        ----------\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        nu : int\n",
    "            Index of the neutrino in the sample\n",
    "            \n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "            Returns the signal PDF for the {psrno}th pulsar and nuind_inp neutrino\n",
    "        '''\n",
    "        ang2 = hvovec(msra, msdec, icra[nu], icdec[nu], rad=True) ** 2      #rad**2\n",
    "        sg = np.deg2rad(icang[nu]) ** 2                                     #rad**2\n",
    "        return np.divide(np.exp(-1 * np.divide(ang2, 2*sg)), (2 * np.pi * sg))      #1/rad**2\n",
    "\n",
    "\n",
    "    @njit(nogil=True)\n",
    "    def S_ik(nu, weight, w_models, gamma_index, ws):\n",
    "\n",
    "        '''\n",
    "        \n",
    "        Calculates S_i as in EQN 8 of 2205.15963\n",
    "        ----------\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        nu : int\n",
    "            Index of the neutrino in the sample\n",
    "\n",
    "        normalized_wt : array\n",
    "            Normalized weights of the pulsars\n",
    "\n",
    "\n",
    "        gamma_index : int\n",
    "            Index of the gamma value in the gamma array\n",
    "\n",
    "        ws : int\n",
    "            Index of the weight model\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "            Returns the signal PDF for the {psrno}th pulsar and nuind_inp neutrino\n",
    "\n",
    "        '''\n",
    "\n",
    "        # si_sing_season_g =\n",
    "        # for i in prange(p):\n",
    "            # sij = S_ijk(nu)\n",
    "            # np.sum(np.multiply(sij, normalized_wt[i][gamma_index][season]))      #1/rad**2\n",
    "\n",
    "\n",
    "\n",
    "        sij = S_ijk(nu)\n",
    "        season = 0\n",
    "        for i in range(10):\n",
    "            if season_walls[i] <= nu and nu < season_walls[i+1]:\n",
    "                season = i\n",
    "                break\n",
    "\n",
    "        return np.sum(np.multiply(sij, np.multiply(w_models[ws], weight[gamma_index][season])/np.sum(np.multiply(w_models[ws], weight[gamma_index][season]))))      #1/rad**2\n",
    "\n",
    "    @njit(parallel=True, nogil=True)\n",
    "    def Sik_sing_s_g(gamma_index, ws):#, wt_acc=wt_acc, w_models=w_models):\n",
    "        '''\n",
    "        Calculates S_i as in EQN 8 of 2205.15963\n",
    "        ----------\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        weight : array\n",
    "            weights of the pulsars\n",
    "\n",
    "        season : int\n",
    "            Season of the neutrino\n",
    "\n",
    "        gamma_index : int\n",
    "            Index of the gamma value in the gamma array\n",
    "\n",
    "        ws : int\n",
    "            Index of the weight model\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "            Returns the signal PDF for the {psrno}th pulsar and nuind_inp neutrino\n",
    "        '''\n",
    "\n",
    "\n",
    "\n",
    "        tmp = []\n",
    "        if ws == -1: #No weights\n",
    "            for nu in prange(len(icra)):\n",
    "                tmp.append(np.sum(S_ijk(nu)))\n",
    "            return np.array(tmp, dtype=np.float64)\n",
    "\n",
    "        for nu in prange(len(icra)):\n",
    "            tmp.append(S_ik(nu, wt_acc, w_models, gamma_index, ws))\n",
    "        return np.array(tmp, dtype=np.float64)\n",
    "    #Pickle\n",
    "    if os.path.isfile(altier_path[0] + f'all_Si_ws_g_s_{len(enus)}_bins_C_wt_perm_{perm}_do_{dec_offest}.pkl'):\n",
    "        print(\"Loading all_Si_ws_g_s from pickle\")\n",
    "        with open(altier_path[0] + f'all_Si_ws_g_s_{len(enus)}_bins_C_wt_perm_{perm}_do_{dec_offest}.pkl', 'rb') as f:\n",
    "            all_Si_ws_g_s = pickle.load(f)\n",
    "        print(\"Loaded all_Si_ws_g_s from pickle with nbins =\", len(enus))\n",
    "    else:\n",
    "\n",
    "\n",
    "        print(\"\\nCalculating S_i for all neutrinos and gammas and weighting schemes...\\n\")\n",
    "\n",
    "        all_Si_ws_g_s = []\n",
    "        tmp = []\n",
    "        tmp_wt_acc = []\n",
    "        tmp_wt_acc_w_dist = []\n",
    "        tmp_wt_acc_w_s1400 = []\n",
    "\n",
    "        for gamma_index in tqdm(prange(4)):\n",
    "            # for season in tqdm(prange(10)):\n",
    "            # tmp.append(Sik_sing_s_g(gamma_index, -1))\n",
    "            tmp_wt_acc.append(Sik_sing_s_g(gamma_index, 0))\n",
    "            tmp_wt_acc_w_dist.append(Sik_sing_s_g(gamma_index, 1))\n",
    "            tmp_wt_acc_w_s1400.append(Sik_sing_s_g(gamma_index, 2))\n",
    "\n",
    "\n",
    "        all_Si_ws_g_s.append([tmp_wt_acc, tmp_wt_acc_w_dist, tmp_wt_acc_w_s1400])\n",
    "        tmp = []\n",
    "        tmp_wt_acc = []\n",
    "        tmp_wt_acc_w_dist = []\n",
    "        tmp_wt_acc_w_s1400 = []\n",
    "        all_Si_ws_g_s = np.asfarray(all_Si_ws_g_s[0])\n",
    "\n",
    "        print(\"Calculated S_i for all neutrinos and gammas and weighting schemes\")\n",
    "        #Save to pickle\n",
    "        with open(altier_path[0] + f'all_Si_ws_g_s_{len(enus)}_bins_C_wt_perm_{perm}_do_{dec_offest}.pkl', 'wb') as f:\n",
    "            pickle.dump(all_Si_ws_g_s, f)\n",
    "\n",
    "\n",
    "    # @jit(nopython=True)\n",
    "    @vectorize(['float64(int64, int64)'], nopython=True,target='parallel')\n",
    "    def Bi_stacked_compute(nu, cone=5):\n",
    "\n",
    "        '''\n",
    "        Calculates B_i as in EQN 9 of 2205.15963\n",
    "        ----------\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        nu : int\n",
    "            Index of the neutrino from IceCube sample\n",
    "        cone : float\n",
    "            Cone angle in degrees.\n",
    "        \n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        float\n",
    "            Returns the background PDF for the {nu}th neutrino\n",
    "        '''\n",
    "\n",
    "        # count = np.sum(np.abs(np.subtract(icdec, icdec[nu])) <= cone)\n",
    "        count=0\n",
    "        for i in prange(len(icdec)):\n",
    "            if abs(icdec[i] - icdec[nu]) <= cone:\n",
    "                count+=1\n",
    "        binwidth = (np.sin(np.deg2rad(icdec[nu] + cone)) - np.sin(np.deg2rad(icdec[nu] - cone)))*2*np.pi\n",
    "        return count/(binwidth * N_ic)           #No units or sr**-1\n",
    "    #Pickle\n",
    "    if os.path.isfile(altier_path[0] + f'all_Bi_C.pkl'):\n",
    "        print(\"Loading all_Bi from pickle...\")\n",
    "        with open(altier_path[0] + f'all_Bi_C.pkl', 'rb') as f:\n",
    "            all_Bi = pickle.load(f)\n",
    "        print(\"Loaded all_Bi from pickle\")\n",
    "    else:\n",
    "        print(\"\\nCalculating Bi for all neutrinos\\n\")\n",
    "        all_Bi = Bi_stacked_compute(np.arange(lnu), 5)\n",
    "        # all_Bi+=1e-90\n",
    "        print(\"\\nCalculated Bi for all neutrinos\")\n",
    "        #Save to pickle\n",
    "        with open(altier_path[0] + f'all_Bi_C.pkl', 'wb') as f:\n",
    "            pickle.dump(all_Bi, f)\n",
    "\n",
    "\n",
    "    arr = np.zeros(10, dtype=np.float64)\n",
    "\n",
    "\n",
    "    @vectorize(['float64(int64, float64, float64, int64)'], nopython=True, target='parallel')\n",
    "    def ns_singleseason_sing_psr_HAT(psrno,gamma, phi0, season):\n",
    "    \n",
    "\n",
    "        tt_upt = t_upt[season]\n",
    "\n",
    "            \n",
    "        l = msdec_bin_indices[psrno]\n",
    "        \n",
    "            \n",
    "        ns_temp = np.zeros(len(enus), dtype=np.float64)\n",
    "        for i in prange(len(enus)):\n",
    "            ns_temp[i] += np.float64(tt_upt * earea[ea_season(season)][l*40 + enus_bin_indices[i]] * phi0 * (enus[i]/(10**14))**gamma)\n",
    "        # temp_ea = np.asarray(earea[ea_season(season)])[l*40 + k]\n",
    "        # return tt_upt * temp_ea * phi0 * ((enu/(10**14))**gamma)     #in s cm2 eV\n",
    "\n",
    "        return np.trapz(ns_temp, enus)     #in s cm2 eV\n",
    "\n",
    "    msdec\n",
    "    def ns_HAT_all_season_all_psr_sing_gamma_wt_wtht_weights(gamma, e_nus=enus, phi0=1):\n",
    "        ns_hat = 0\n",
    "        ns_hat_wt = 0\n",
    "        ns_hat_wt_dist = 0\n",
    "        ns_hat_wt_s1400 = 0\n",
    "        for season in tqdm(prange(10)):\n",
    "\n",
    "            ns_hat = ns_singleseason_sing_psr_HAT(prange(p), gamma, phi0, season)\n",
    "            ns_hat_wt += ns_hat\n",
    "            ns_hat_wt_dist += np.dot(w_models[1]/ np.sum(w_models[1]) , ns_hat)\n",
    "            ns_hat_wt_s1400 += np.dot(w_models[2]/ np.sum(w_models[2]), ns_hat)\n",
    "        return np.array([np.sum(ns_hat_wt), ns_hat_wt_dist, ns_hat_wt_s1400], dtype=np.float64)\n",
    "    #Pickle\n",
    "    arr = []\n",
    "    if os.path.isfile(altier_path[0] + f'ns_all_ws_{len(enus)}_bins_C_wt_perm_{perm}_do_{dec_offest}.pkl'):\n",
    "        print(\"Loading ns_hat from pickle...\")\n",
    "        with open(altier_path[0] + f'ns_all_ws_{len(enus)}_bins_C_wt_perm_{perm}_do_{dec_offest}.pkl', 'rb') as f:\n",
    "            arr = pickle.load(f)\n",
    "        print(\"Loaded ns_hat from pickle with nbins =\", len(enus))\n",
    "    else:\n",
    "        print(\"\\nCalculating ns_HAT for all gamma and weighting schemes...\\n\")\n",
    "\n",
    "        arr=[]\n",
    "        for gamma in prange(len(gamma_arr)):\n",
    "            tmp = ns_HAT_all_season_all_psr_sing_gamma_wt_wtht_weights(gamma_arr[gamma])\n",
    "            np.savetxt('outputs/ns_hat_wt_wt_gamma_{}.txt'.format(gamma_arr[gamma]), tmp)\n",
    "            arr.append(tmp)\n",
    "            tmp = []\n",
    "\n",
    "        arr = np.array(arr, dtype=np.float64)\n",
    "        with open(altier_path[0] + f'ns_all_ws_{len(enus)}_bins_C_wt_perm_{perm}_do_{dec_offest}.pkl', 'wb') as f:\n",
    "            pickle.dump(arr, f)\n",
    "        print(\"\\nCalculationed ns_HAT for all gamma and weighting schemes\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    @njit(nogil=True)\n",
    "    def TS_for_all_psrs2(nsa):  \n",
    "        return Ts_arr2(nsa, t2mp, all_Bi, Ns) \n",
    "\n",
    "\n",
    "    @jit(nopython=True)\n",
    "    def Pr(x, Ns, S, B):\n",
    "        nsN = x/Ns\n",
    "        return np.add(np.multiply(nsN , S), np.multiply(np.subtract(1, nsN), B))\n",
    "\n",
    "\n",
    "\n",
    "    @njit(nogil=True)\n",
    "    def TS_st_vec(x, S, B, Ns):\n",
    "        nsN = x/Ns\n",
    "        pr = np.add(np.multiply(nsN , S), np.multiply(np.subtract(1, nsN), B))\n",
    "        return np.sum(np.asfarray(2*np.log(pr/B)))\n",
    "\n",
    "    lnu = 1134450\n",
    "    Ns = lnu#np.count_nonzero(nuind+1)\n",
    "\n",
    "\n",
    "    phio = np.logspace(-38, -20, 1000)\n",
    "    print('\\nCALCULATING TS FOR ALL PSRS FOR ALL GAMMAS FOR ALL WEIGHTS\\n')\n",
    "\n",
    "    all_TSS = []\n",
    "    for ws in prange(3):\n",
    "        tmpp = []\n",
    "        print(\"ws = {}\".format(ws))\n",
    "        for gamma in prange(len(gamma_arr)):\n",
    "            print(\"gamma = {}\".format(gamma))\n",
    "            # tmp = np.zeros(len(phio))\n",
    "            # for season in tqdm(range(10)):\n",
    "            t2mp = np.asfarray(all_Si_ws_g_s[ws][gamma])\n",
    "            @njit(nogil=True)\n",
    "            def TS_for_all_psrs2(nsa):  \n",
    "                return TS_st_vec(nsa, t2mp, all_Bi, Ns)      #No units\n",
    "            temp = []\n",
    "            for phi in tqdm(prange(len(phio))):\n",
    "                temp.append(TS_for_all_psrs2(arr[gamma][ws]*phio[phi]))\n",
    "            tmpp.append(temp)\n",
    "            temp = []\n",
    "        all_TSS.append(tmpp)\n",
    "        tmpp = []\n",
    "\n",
    "    print('\\nCALCULATED TS FOR ALL PSRS FOR ALL GAMMAS FOR ALL WEIGHTS')\n",
    "\n",
    "\n",
    "\n",
    "    all_TSS = np.array(all_TSS, dtype=np.float64)\n",
    "\n",
    "\n",
    "    for w in range(3):\n",
    "        for g in range(len(gamma_arr)):\n",
    "            print(min(all_TSS[w][g]), max(all_TSS[w][g]))\n",
    "            # np.savetxt(f'TS_w{w}_g{g}.txt', all_TSS[w][g])\n",
    "            \n",
    "        print('wt\\n')\n",
    "\n",
    "    with open(altier_path[0] + f'all_TSS_{len(enus)}_bins_C_wt_perm_{perm}_do_{dec_offest}.pkl', 'wb') as f:\n",
    "        pickle.dump(all_TSS, f)\n",
    "    #Plotting\n",
    "\n",
    "    all_TSS = np.asarray(all_TSS)\n",
    "    gamma_arr = np.asarray(gamma_arr)\n",
    "\n",
    "    all_e_UL = []\n",
    "    e_decade = [1e13, 1e14, 1e15, 1e16, 1e17]\n",
    "    for e_UL in e_decade:\n",
    "        e2dfde = []\n",
    "\n",
    "        for gamma in prange(len(gamma_arr)):\n",
    "            temp = []\n",
    "            for phi in range(len(phio)):\n",
    "                temp.append( e_UL**2 * dfde(e_UL, gamma_arr[gamma], phio[phi]))        #in eV\n",
    "            e2dfde.append(temp)\n",
    "        e2dfde = np.asarray(e2dfde)\n",
    "\n",
    "        all_e_UL.append(e2dfde)\n",
    "    mark = ['^', 'o', 's', 'd']\n",
    "    all_TSS.shape\n",
    "    all_TSS.shape\n",
    "    for w in range(3):\n",
    "        for g in range(3):\n",
    "            print(phio[np.argmax(all_TSS[w][g])])\n",
    "    max(all_TSS[1][2])\n",
    "\n",
    "    tete = np.float64('2.543345761304638e-23 9.396648314954749e-24 1.4526539259467783e-24 2.3408272761782943e-23 8.296958520834915e-24 1.2305240043592616e-24 1.61141427725301e-23 5.711586478126447e-24 8.470868266557419e-25'.split(' '))\n",
    "\n",
    "\n",
    "    all_UL = []\n",
    "    for ws in range(3):\n",
    "        ul_all_gamma = []\n",
    "        for gamma in prange(len(gamma_arr)):\n",
    "            temp = []\n",
    "            for i in all_e_UL:\n",
    "                dist_g = interp.interp1d(all_TSS[ws][gamma], i[gamma]/1e9)\n",
    "                temp.append(dist_g(-3.84))\n",
    "\n",
    "            ul_all_gamma.append(temp)\n",
    "        all_UL.append(ul_all_gamma)\n",
    "    e2dfde = all_e_UL[1]\n",
    "    # plt.style.use('default')\n",
    "    font = {'family': 'serif',\n",
    "            'weight': 'bold',\n",
    "            'size': 22,\n",
    "            'color':  'black',\n",
    "            }\n",
    "    smallerfont = {'family': 'serif',\n",
    "            'color':  'black',\n",
    "            'weight': 'bold',\n",
    "            'size': 15,\n",
    "            }\n",
    "\n",
    "    axesfont = {'family': 'serif',\n",
    "            'color':  'black',\n",
    "            'weight': 'bold',\n",
    "            'size': 17,\n",
    "            }\n",
    "\n",
    "    fig, axs = plt.subplots(1,3, figsize=(18, 6))\n",
    "\n",
    "    for gamma in [ 1, 2, 3]:#range(4):\n",
    "        \n",
    "        for i in range(3):\n",
    "            axs[i].plot(e2dfde[gamma]/1e9, all_TSS[i][gamma], label='$\\Gamma$ = ' + str(gamma_arr[gamma]), lw=2.2)# + ' with wt')    #in GeV\n",
    "\n",
    "        \n",
    "\n",
    "    axs[0].set_title('Weighting scheme:  $\\mathsf{\\mathbf{w_{model} = 1}}$', fontdict=smallerfont)\n",
    "    axs[1].set_title('Weighting scheme:  $\\mathsf{\\mathbf{w_{model} = \\dfrac{1}{d_{DM}^2}}}$' , fontdict=smallerfont)\n",
    "    axs[2].set_title('Weighting scheme:  $\\mathsf{\\mathbf{w_{model} = s_{1400}}}$', fontdict=smallerfont)\n",
    "\n",
    "\n",
    "    for i in range(3):\n",
    "        \n",
    "        axs[i].legend(prop={'size':14}, framealpha=0, loc='lower left')\n",
    "        axs[i].hlines(-3.84, 1e-20, 1e-5, linestyles='dashed', lw=2.2, ls='-.', label='95 % UPPER LIMIT $TS = -3.84$', color='lightcoral')\n",
    "        axs[i].set_xscale('log')\n",
    "        axs[i].set_xlabel('$\\mathsf{\\mathbf{E^2_{\\u03BD} \\dfrac{dF}{dE_{\\u03BD}}}}$ at 100 TeV ($\\mathsf{\\mathbf{GeV}}$ $\\mathsf{\\mathbf{s^{-1}}}$ $\\mathsf{\\mathbf{cm^{-2}}}$ $\\mathsf{\\mathbf{sr^{-1}}}$)', fontdict=axesfont)\n",
    "        axs[i].set_ylabel('TS', fontdict=axesfont, fontsize=20)\n",
    "        axs[i].xaxis.set_tick_params(labelsize=15)\n",
    "        axs[i].yaxis.set_tick_params(labelsize=15)\n",
    "        \n",
    "        axs[i].set_ylim(-220, 90)\n",
    "        axs[i].set_xlim(0.95e-19, 1e-6)\n",
    "\n",
    "    plt.suptitle('TS vs Total Neutrino Flux at 100 TeV', fontweight='bold', fontsize=20, fontfamily='serif')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'outputs/TS_vs_E2dfde_all_w_model_bins={len(enus)}_C_wt_perm_{perm}_do_{dec_offest}.png')\n",
    "    # plt.show()\n",
    "    print(f'\\nTS_vs_E2dfde_all_w_model_bins={len(enus)}_C_wt_perm_{perm}_do_{dec_offest}.png\\nDONE')\n",
    "    #SIMILAR PLOTS FOR 95% UPPER LIMIT \n",
    "    fig, axs = plt.subplots(1,3, figsize=(18, 6))\n",
    "\n",
    "\n",
    "\n",
    "    for i in range(3):\n",
    "        for gamma in range(1, len(gamma_arr)):\n",
    "\n",
    "            axs[i].plot(np.divide(e_decade, 1e9), np.multiply(all_UL[i][gamma], 3), label='$\\Gamma$ = ' + str(gamma_arr[gamma]), lw=2.2, ls='-')# + ' with wt')    #in GeV\n",
    "\n",
    "        \n",
    "        axs[i].set_xscale('log')\n",
    "        axs[i].set_yscale('log')\n",
    "        axs[i].set_xlabel('E$_{\\u03BD}$ (GeV)', fontdict=axesfont)\n",
    "        axs[i].set_ylabel('$\\mathsf{\\mathbf{E^2_{\\u03BD} \\dfrac{dF}{dE_{\\u03BD}}}}$ at 100 TeV ($\\mathsf{\\mathbf{GeV}}$ $\\mathsf{\\mathbf{s^{-1}}}$ $\\mathsf{\\mathbf{cm^{-2}}}$ $\\mathsf{\\mathbf{sr^{-1}}}$)', fontdict=axesfont)\n",
    "        axs[i].xaxis.set_tick_params(labelsize=15)\n",
    "        axs[i].yaxis.set_tick_params(labelsize=15)\n",
    "        \n",
    "        axs[i].legend(prop={'size':14}, framealpha=0, loc='lower left')\n",
    "\n",
    "\n",
    "    axs[0].set_title('Weighting scheme:  $\\mathsf{\\mathbf{w_{model} = 1}}$', fontdict=smallerfont)\n",
    "    axs[1].set_title('Weighting scheme:  $\\mathsf{\\mathbf{w_{model} = \\dfrac{1}{d_{DM}^2}}}$' , fontdict=smallerfont)\n",
    "    axs[2].set_title('Weighting scheme:  $\\mathsf{\\mathbf{w_{model} = s_{1400}}}$', fontdict=smallerfont)\n",
    "\n",
    "\n",
    "    plt.suptitle('95% UL of Total Energy Flux vs Neutrino Energy', fontweight='bold', fontsize=20, fontfamily='serif')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'outputs/UL_all_w_model_bins={len(enus)}_C_wt_perm_{perm}_do_{dec_offest}.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
